# data_cleaner.py - æ•°æ®æ¸…æ´—
# =============================================================================

import pandas as pd
import numpy as np
from typing import Dict, List, Optional, Tuple, Any
from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler
from sklearn.impute import SimpleImputer, KNNImputer
from scipy import stats
import warnings
warnings.filterwarnings('ignore')

from logger import TradingLogger
from utils import ConfigManager, DataUtils


class OutlierDetector:
    """å¼‚å¸¸å€¼æ£€æµ‹å™¨"""
    
    @staticmethod
    def detect_iqr(data: pd.Series, factor: float = 1.5) -> np.ndarray:
        """IQRæ–¹æ³•æ£€æµ‹å¼‚å¸¸å€¼"""
        Q1 = data.quantile(0.25)
        Q3 = data.quantile(0.75)
        IQR = Q3 - Q1
        
        lower_bound = Q1 - factor * IQR
        upper_bound = Q3 + factor * IQR
        
        return (data < lower_bound) | (data > upper_bound)
    
    @staticmethod
    def detect_zscore(data: pd.Series, threshold: float = 3.0) -> np.ndarray:
        """Z-Scoreæ–¹æ³•æ£€æµ‹å¼‚å¸¸å€¼"""
        z_scores = np.abs(stats.zscore(data.dropna()))
        outlier_mask = np.zeros(len(data), dtype=bool)
        outlier_mask[data.notna()] = z_scores > threshold
        return outlier_mask
    
    @staticmethod
    def detect_modified_zscore(data: pd.Series, threshold: float = 3.5) -> np.ndarray:
        """ä¿®æ­£Z-Scoreæ–¹æ³•æ£€æµ‹å¼‚å¸¸å€¼"""
        median = data.median()
        mad = np.median(np.abs(data - median))
        
        if mad == 0:
            return np.zeros(len(data), dtype=bool)
        
        modified_z_scores = 0.6745 * (data - median) / mad
        return np.abs(modified_z_scores) > threshold
    
    @staticmethod
    def detect_price_outliers(
        df: pd.DataFrame,
        price_cols: List[str] = ['open', 'high', 'low', 'close'],
        volume_col: str = 'volume',
        method: str = 'iqr'
    ) -> Dict[str, np.ndarray]:
        """æ£€æµ‹ä»·æ ¼æ•°æ®å¼‚å¸¸å€¼"""
        outliers = {}
        
        for col in price_cols:
            if col in df.columns:
                if method == 'iqr':
                    outliers[col] = OutlierDetector.detect_iqr(df[col])
                elif method == 'zscore':
                    outliers[col] = OutlierDetector.detect_zscore(df[col])
                elif method == 'modified_zscore':
                    outliers[col] = OutlierDetector.detect_modified_zscore(df[col])
        
        # æˆäº¤é‡å¼‚å¸¸å€¼æ£€æµ‹
        if volume_col in df.columns:
            outliers[volume_col] = OutlierDetector.detect_modified_zscore(df[volume_col])
        
        # ä»·æ ¼ä¸€è‡´æ€§æ£€æŸ¥
        if all(col in df.columns for col in ['high', 'low', 'close']):
            price_inconsistent = (df['high'] < df['low']) | (df['close'] > df['high']) | (df['close'] < df['low'])
            outliers['price_inconsistent'] = price_inconsistent.values
        
        return outliers


class DataCleaner:
    """æ•°æ®æ¸…æ´—å™¨"""
    
    def __init__(self, config_path: str = "config.yaml"):
        self.config = ConfigManager(config_path)
        self.logger = TradingLogger().get_logger("DATA_CLEANER")
        
        # æ¸…æ´—é…ç½®
        self.outlier_method = self.config.get("cleaner.outlier_method", "modified_zscore")
        self.outlier_threshold = self.config.get("cleaner.outlier_threshold", 3.5)
        self.imputation_method = self.config.get("cleaner.imputation_method", "linear")
        self.scaling_method = self.config.get("cleaner.scaling_method", "robust")
        
        # å¼‚å¸¸å€¼å¤„ç†ç­–ç•¥
        self.outlier_strategy = self.config.get("cleaner.outlier_strategy", "cap")  # cap, remove, interpolate
        
        # åˆå§‹åŒ–ç¼©æ”¾å™¨
        self.scalers = {
            'standard': StandardScaler(),
            'minmax': MinMaxScaler(),
            'robust': RobustScaler()
        }
        
        self.fitted_scalers: Dict[str, Any] = {}
    
    def clean_market_data(
        self,
        df: pd.DataFrame,
        symbol: str,
        detect_outliers: bool = True,
        handle_missing: bool = True,
        normalize_data: bool = True
    ) -> Tuple[pd.DataFrame, Dict[str, Any]]:
        """
        æ¸…æ´—å¸‚åœºæ•°æ®
        
        Args:
            df: åŸå§‹æ•°æ®
            symbol: äº¤æ˜“å¯¹
            detect_outliers: æ˜¯å¦æ£€æµ‹å¼‚å¸¸å€¼
            handle_missing: æ˜¯å¦å¤„ç†ç¼ºå¤±å€¼
            normalize_data: æ˜¯å¦æ ‡å‡†åŒ–æ•°æ®
        
        Returns:
            æ¸…æ´—åçš„æ•°æ®å’Œè´¨é‡æŠ¥å‘Š
        """
        original_shape = df.shape
        quality_report = {
            'symbol': symbol,
            'original_rows': original_shape[0],
            'original_cols': original_shape[1],
            'cleaning_steps': [],
            'outliers_detected': {},
            'missing_values_filled': {},
            'data_quality_score': 0.0
        }
        
        df_cleaned = df.copy()
        
        try:
            # 1. åŸºç¡€æ•°æ®éªŒè¯
            df_cleaned = self._validate_basic_data(df_cleaned, quality_report)
            
            # 2. å¼‚å¸¸å€¼æ£€æµ‹å’Œå¤„ç†
            if detect_outliers:
                df_cleaned = self._handle_outliers(df_cleaned, quality_report)
            
            # 3. ç¼ºå¤±å€¼å¤„ç†
            if handle_missing:
                df_cleaned = self._handle_missing_values(df_cleaned, quality_report)
            
            # 4. æ•°æ®æ ‡å‡†åŒ–
            if normalize_data:
                df_cleaned = self._normalize_data(df_cleaned, symbol, quality_report)
            
            # 5. æœ€ç»ˆè´¨é‡è¯„ä¼°
            quality_report['final_rows'] = len(df_cleaned)
            quality_report['data_quality_score'] = self._calculate_quality_score(df_cleaned, quality_report)
            
            self.logger.info(f"{symbol} æ•°æ®æ¸…æ´—å®Œæˆ - è´¨é‡è¯„åˆ†: {quality_report['data_quality_score']:.2f}")
            
            return df_cleaned, quality_report
            
        except Exception as e:
            self.logger.error(f"æ•°æ®æ¸…æ´—å¤±è´¥ {symbol}: {e}")
            return df, quality_report
    
    def _validate_basic_data(self, df: pd.DataFrame, quality_report: Dict[str, Any]) -> pd.DataFrame:
        """åŸºç¡€æ•°æ®éªŒè¯"""
        initial_rows = len(df)
        
        # ç§»é™¤å®Œå…¨é‡å¤çš„è¡Œ
        df = df.drop_duplicates()
        duplicates_removed = initial_rows - len(df)
        
        if duplicates_removed > 0:
            quality_report['cleaning_steps'].append(f"ç§»é™¤é‡å¤è¡Œ: {duplicates_removed}")
        
        # æ—¶é—´åºåˆ—æ’åº
        if 'timestamp' in df.columns:
            df = df.sort_values('timestamp')
        
        # ä»·æ ¼æ•°æ®åŸºç¡€éªŒè¯
        price_cols = ['open', 'high', 'low', 'close']
        valid_price_cols = [col for col in price_cols if col in df.columns]
        
        for col in valid_price_cols:
            # ç§»é™¤éæ­£æ•°ä»·æ ¼
            invalid_prices = (df[col] <= 0) | (~np.isfinite(df[col]))
            if invalid_prices.any():
                df = df[~invalid_prices]
                quality_report['cleaning_steps'].append(f"ç§»é™¤æ— æ•ˆ{col}ä»·æ ¼: {invalid_prices.sum()}")
        
        # æˆäº¤é‡éªŒè¯
        if 'volume' in df.columns:
            invalid_volume = (df['volume'] < 0) | (~np.isfinite(df['volume']))
            if invalid_volume.any():
                df = df[~invalid_volume]
                quality_report['cleaning_steps'].append(f"ç§»é™¤æ— æ•ˆæˆäº¤é‡: {invalid_volume.sum()}")
        
        return df.reset_index(drop=True)
    
    def _handle_outliers(self, df: pd.DataFrame, quality_report: Dict[str, Any]) -> pd.DataFrame:
        """å¼‚å¸¸å€¼å¤„ç†"""
        price_cols = ['open', 'high', 'low', 'close']
        volume_col = 'volume'
        
        # æ£€æµ‹å¼‚å¸¸å€¼
        outliers = OutlierDetector.detect_price_outliers(
            df, price_cols, volume_col, self.outlier_method
        )
        
        quality_report['outliers_detected'] = {
            col: int(mask.sum()) for col, mask in outliers.items()
        }
        
        # å¤„ç†å¼‚å¸¸å€¼
        for col, outlier_mask in outliers.items():
            if outlier_mask.any() and col in df.columns:
                outlier_count = outlier_mask.sum()
                
                if self.outlier_strategy == 'remove':
                    df = df[~outlier_mask]
                    quality_report['cleaning_steps'].append(f"ç§»é™¤{col}å¼‚å¸¸å€¼: {outlier_count}")
                
                elif self.outlier_strategy == 'cap':
                    if col != 'price_inconsistent':
                        # ç”¨åˆ†ä½æ•°æˆªæ–­
                        q1, q99 = df[col].quantile([0.01, 0.99])
                        df.loc[outlier_mask, col] = np.clip(df.loc[outlier_mask, col], q1, q99)
                        quality_report['cleaning_steps'].append(f"æˆªæ–­{col}å¼‚å¸¸å€¼: {outlier_count}")
                
                elif self.outlier_strategy == 'interpolate':
                    df.loc[outlier_mask, col] = np.nan
                    df[col] = df[col].interpolate(method='linear')
                    quality_report['cleaning_steps'].append(f"æ’å€¼{col}å¼‚å¸¸å€¼: {outlier_count}")
        
        return df.reset_index(drop=True)
    
    def _handle_missing_values(self, df: pd.DataFrame, quality_report: Dict[str, Any]) -> pd.DataFrame:
        """ç¼ºå¤±å€¼å¤„ç†"""
        missing_before = df.isnull().sum()
        columns_with_missing = missing_before[missing_before > 0].index.tolist()
        
        if not columns_with_missing:
            return df
        
        for col in columns_with_missing:
            missing_count = missing_before[col]
            missing_ratio = missing_count / len(df)
            
            # å¦‚æœç¼ºå¤±æ¯”ä¾‹è¿‡é«˜ï¼Œè€ƒè™‘åˆ é™¤åˆ—
            if missing_ratio > 0.5:
                df = df.drop(columns=[col])
                quality_report['cleaning_steps'].append(f"åˆ é™¤ç¼ºå¤±ç‡è¿‡é«˜çš„åˆ—{col}: {missing_ratio:.2%}")
                continue
            
            # æ ¹æ®åˆ—ç±»å‹é€‰æ‹©å¡«å……æ–¹æ³•
            if col in ['open', 'high', 'low', 'close']:
                # ä»·æ ¼æ•°æ®ç”¨çº¿æ€§æ’å€¼
                df[col] = df[col].interpolate(method='linear')
                
            elif col == 'volume':
                # æˆäº¤é‡ç”¨å‰å‘å¡«å……
                df[col] = df[col].fillna(method='ffill').fillna(method='bfill')
                
            else:
                # å…¶ä»–æ•°æ®ç”¨ä¸­ä½æ•°å¡«å……
                df[col] = df[col].fillna(df[col].median())
            
            filled_count = missing_count - df[col].isnull().sum()
            quality_report['missing_values_filled'][col] = int(filled_count)
        
        # åˆ é™¤ä»æœ‰ç¼ºå¤±å€¼çš„è¡Œ
        remaining_missing = df.isnull().any(axis=1).sum()
        if remaining_missing > 0:
            df = df.dropna()
            quality_report['cleaning_steps'].append(f"åˆ é™¤å‰©ä½™ç¼ºå¤±å€¼è¡Œ: {remaining_missing}")
        
        return df.reset_index(drop=True)
    
    def _normalize_data(self, df: pd.DataFrame, symbol: str, quality_report: Dict[str, Any]) -> pd.DataFrame:
        """æ•°æ®æ ‡å‡†åŒ–"""
        normalize_cols = []
        
        # ç¡®å®šéœ€è¦æ ‡å‡†åŒ–çš„åˆ—
        price_cols = ['open', 'high', 'low', 'close']
        for col in price_cols:
            if col in df.columns:
                normalize_cols.append(col)
        
        if 'volume' in df.columns:
            normalize_cols.append('volume')
        
        if not normalize_cols:
            return df
        
        # é€‰æ‹©ç¼©æ”¾å™¨
        scaler = self.scalers[self.scaling_method].copy()
        
        # æ ‡å‡†åŒ–æ•°æ®
        try:
            df_scaled = df.copy()
            scaled_values = scaler.fit_transform(df[normalize_cols])
            df_scaled[normalize_cols] = scaled_values
            
            # ä¿å­˜ç¼©æ”¾å™¨ç”¨äºå®æ—¶æ•°æ®å¤„ç†
            self.fitted_scalers[symbol] = scaler
            
            quality_report['cleaning_steps'].append(f"æ ‡å‡†åŒ–åˆ—: {normalize_cols}")
            
            return df_scaled
            
        except Exception as e:
            self.logger.error(f"æ•°æ®æ ‡å‡†åŒ–å¤±è´¥: {e}")
            return df
    
    def _calculate_quality_score(self, df: pd.DataFrame, quality_report: Dict[str, Any]) -> float:
        """è®¡ç®—æ•°æ®è´¨é‡è¯„åˆ†"""
        score = 100.0
        
        # æ ¹æ®æ•°æ®å®Œæ•´æ€§æ‰£åˆ†
        missing_ratio = df.isnull().sum().sum() / (len(df) * len(df.columns))
        score -= missing_ratio * 50
        
        # æ ¹æ®å¼‚å¸¸å€¼æ¯”ä¾‹æ‰£åˆ†
        total_outliers = sum(quality_report.get('outliers_detected', {}).values())
        outlier_ratio = total_outliers / len(df) if len(df) > 0 else 0
        score -= outlier_ratio * 30
        
        # æ ¹æ®æ•°æ®é‡æ‰£åˆ†
        if len(df) < 100:
            score -= 20
        elif len(df) < 1000:
            score -= 10
        
        return max(0.0, min(100.0, score))
    
    def transform_realtime_data(self, data: Dict[str, float], symbol: str) -> Dict[str, float]:
        """è½¬æ¢å®æ—¶æ•°æ®ï¼ˆä½¿ç”¨å·²è®­ç»ƒçš„ç¼©æ”¾å™¨ï¼‰"""
        if symbol not in self.fitted_scalers:
            return data
        
        try:
            scaler = self.fitted_scalers[symbol]
            
            # æå–éœ€è¦æ ‡å‡†åŒ–çš„ç‰¹å¾
            price_cols = ['open', 'high', 'low', 'close']
            feature_cols = [col for col in price_cols if col in data]
            
            if 'volume' in data:
                feature_cols.append('volume')
            
            if not feature_cols:
                return data
            
            # æ„å»ºç‰¹å¾æ•°ç»„
            features = np.array([[data[col] for col in feature_cols]])
            
            # æ ‡å‡†åŒ–
            scaled_features = scaler.transform(features)[0]
            
            # æ›´æ–°æ•°æ®
            scaled_data = data.copy()
            for i, col in enumerate(feature_cols):
                scaled_data[col] = float(scaled_features[i])
            
            return scaled_data
            
        except Exception as e:
            self.logger.error(f"å®æ—¶æ•°æ®è½¬æ¢å¤±è´¥ {symbol}: {e}")
            return data
    
    def get_data_statistics(self, df: pd.DataFrame) -> Dict[str, Any]:
        """è·å–æ•°æ®ç»Ÿè®¡ä¿¡æ¯"""
        return {
            'total_rows': len(df),
            'total_columns': len(df.columns),
            'numeric_columns': len(df.select_dtypes(include=[np.number]).columns),
            'missing_values': df.isnull().sum().to_dict(),
            'data_types': df.dtypes.astype(str).to_dict(),
            'memory_usage': f"{df.memory_usage(deep=True).sum() / 1024 / 1024:.2f} MB",
            'time_range': {
                'start': df['timestamp'].min() if 'timestamp' in df.columns else None,
                'end': df['timestamp'].max() if 'timestamp' in df.columns else None
            },
            'price_summary': df[['open', 'high', 'low', 'close']].describe().to_dict() if all(col in df.columns for col in ['open', 'high', 'low', 'close']) else {}
        }


# é›†æˆæµ‹è¯•å‡½æ•°
async def test_data_layer():
    """æµ‹è¯•æ•°æ®å±‚åŠŸèƒ½"""
    logger = TradingLogger().get_logger("DATA_LAYER_TEST")
    logger.info("ğŸ§ª å¼€å§‹æ•°æ®å±‚æµ‹è¯•...")
    
    # æµ‹è¯•æ•°æ®é‡‡é›†å™¨
    collector = MarketDataCollector()
    
    # æ·»åŠ æ•°æ®å›è°ƒ
    async def data_callback(data_type: str, data: Dict[str, Any]):
        logger.info(f"æ¥æ”¶åˆ°{data_type}æ•°æ®: {data.get('symbol', 'UNKNOWN')}")
    
    collector.add_data_callback(data_callback)
    
    # æµ‹è¯•æ•°æ®æ¸…æ´—å™¨
    cleaner = DataCleaner()
    
    # ç”Ÿæˆæµ‹è¯•æ•°æ®
    test_data = pd.DataFrame({
        'timestamp': range(1000),
        'open': np.random.normal(50000, 1000, 1000),
        'high': np.random.normal(51000, 1000, 1000),
        'low': np.random.normal(49000, 1000, 1000),
        'close': np.random.normal(50000, 1000, 1000),
        'volume': np.random.exponential(1000, 1000)
    })
    
    # æ·»åŠ ä¸€äº›å¼‚å¸¸å€¼å’Œç¼ºå¤±å€¼
    test_data.loc[10:15, 'close'] = np.nan
    test_data.loc[50, 'high'] = 100000  # å¼‚å¸¸å€¼
    test_data.loc[100, 'volume'] = -100  # æ— æ•ˆå€¼
    
    logger.info("æ¸…æ´—æµ‹è¯•æ•°æ®...")
    cleaned_data, quality_report = cleaner.clean_market_data(test_data, "BTCUSDT")
    
    logger.info(f"æ¸…æ´—ç»“æœ: {quality_report['data_quality_score']:.2f}åˆ†")
    logger.info(f"å¤„ç†æ­¥éª¤: {quality_report['cleaning_steps']}")
    
    logger.info("âœ… æ•°æ®å±‚æµ‹è¯•å®Œæˆ")

if __name__ == "__main__":
    asyncio.run(test_data_layer())